{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from algo_reasoning.src.sampler import CLRSDataset\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homophily_measure(adj_matrix, classes):\n",
    "    \"\"\"\n",
    "    Compute the homophily measure of the graph\n",
    "    \"\"\"\n",
    "    n = adj_matrix.shape[0]\n",
    "    homophily = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        node_homophily = 0\n",
    "        for j in range(n):\n",
    "            if classes[i] == classes[j]:\n",
    "                node_homophily += adj_matrix[i, j]\n",
    "\n",
    "        node_homophily /= adj_matrix[i].sum()\n",
    "        homophily += node_homophily\n",
    "\n",
    "    homophily /= n\n",
    "    return homophily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbiased_homophily(adj_matrix, classes):\n",
    "    \"\"\"\n",
    "    Compute the unbiased homophily measure of the graph\n",
    "    As described in (https://arxiv.org/pdf/2412.09663)\n",
    "    \"\"\"\n",
    "    classes_unique = torch.unique(classes).int()\n",
    "    n_classes = classes_unique.size(0)\n",
    "    n_nodes = adj_matrix.size(0)\n",
    "    n_edges = 0\n",
    "\n",
    "    class_adj_matrix = torch.zeros(n_classes, n_classes)\n",
    "\n",
    "    edges_classes = dict()\n",
    "\n",
    "    for c1 in classes_unique.tolist():\n",
    "        for c2 in classes_unique.tolist():\n",
    "            edges_classes[(c1, c2)] = []\n",
    "\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(i + 1, n_nodes):\n",
    "            if adj_matrix[i, j] > 0:\n",
    "                n_edges += 1\n",
    "                class_i = classes[i].item()\n",
    "                class_j = classes[j].item()\n",
    "\n",
    "                edges_classes[(class_i, class_j)].append((i, j))\n",
    "\n",
    "    for c1 in classes_unique.tolist():\n",
    "        for c2 in classes_unique.tolist():\n",
    "            class_adj_matrix[c1, c2] = len(edges_classes[(c1, c2)]) + len(edges_classes[(c2, c1)])\n",
    "\n",
    "            if c1 == c2:\n",
    "                class_adj_matrix[c1, c2] /= n_edges\n",
    "            else:\n",
    "                class_adj_matrix[c1, c2] /= 2*n_edges\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for c1 in classes_unique.tolist():\n",
    "        filtered_classes = classes_unique[classes_unique > c1].tolist()\n",
    "        for c2 in filtered_classes:\n",
    "            numerator += torch.sqrt(class_adj_matrix[c1, c1]*class_adj_matrix[c2, c2]) - class_adj_matrix[c1, c2]\n",
    "            denominator += torch.sqrt(class_adj_matrix[c1, c1]*class_adj_matrix[c2, c2]) + class_adj_matrix[c1, c2]\n",
    "   \n",
    "    return (numerator/denominator).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_homophilies(homophilies):\n",
    "    hfont = {'fontname':'Courier New', \"fontweight\":\"bold\"}\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(30, 5), dpi=80)\n",
    "\n",
    "    for i, column in enumerate(homophilies[\"graph_size\"]):\n",
    "        plt.subplot(1,5,i + 1)\n",
    "        plt.subplots_adjust(top=0.8)\n",
    "        sns.histplot(homophilies[\"homophilies\"][i], kde=True, bins=15)\n",
    "        plt.rc('axes', titlesize=14)\n",
    "        plt.title(\"Graph Size = \"+str(homophilies[\"graph_size\"][i]), **hfont)\n",
    "        if i > 0:\n",
    "            plt.ylabel('')\n",
    "\n",
    "    plt.rc('figure', titlesize=20)\n",
    "    #plt.suptitle(\"Homophily Distribution - Articulation Points\", **hfont)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Articulation Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"articulation_points\"]\n",
    "\n",
    "batch_size = 64\n",
    "articulation_points_16 = CLRSDataset(algorithms, [16], batch_size, 1000, seed=7, algorithms_args={'p': [0.05, 0.1, 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45]})\n",
    "articulation_points_13 = CLRSDataset(algorithms, [13], batch_size, 1000, seed=7, algorithms_args={'p': [0.05, 0.1, 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45]})\n",
    "articulation_points_11 = CLRSDataset(algorithms, [11], batch_size, 1000, seed=7, algorithms_args={'p': [0.05, 0.1, 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45]})\n",
    "articulation_points_7 = CLRSDataset(algorithms, [7], batch_size*2, 1000, seed=7, algorithms_args={'p': [0.05, 0.1, 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45]})\n",
    "articulation_points_4 = CLRSDataset(algorithms, [4], batch_size*4, 1000, seed=7, algorithms_args={'p': [0.05, 0.1, 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_16 = next(iter(articulation_points_16))\n",
    "obj_13 = next(iter(articulation_points_13))\n",
    "obj_11 = next(iter(articulation_points_11))\n",
    "obj_7 = next(iter(articulation_points_7))\n",
    "obj_4 = next(iter(articulation_points_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies_16 = [unbiased_homophily(obj_16.inputs.A[i], obj_16.outputs.is_cut[i]) for i in range(batch_size) if torch.sum(obj_16.outputs.is_cut[i]).item() > 0]\n",
    "homophilies_13 = [unbiased_homophily(obj_13.inputs.A[i], obj_13.outputs.is_cut[i]) for i in range(batch_size) if torch.sum(obj_13.outputs.is_cut[i]).item() > 0]\n",
    "homophilies_11 = [unbiased_homophily(obj_11.inputs.A[i], obj_11.outputs.is_cut[i]) for i in range(batch_size) if torch.sum(obj_11.outputs.is_cut[i]).item() > 0]\n",
    "homophilies_7 = [unbiased_homophily(obj_7.inputs.A[i], obj_7.outputs.is_cut[i]) for i in range(batch_size*2) if torch.sum(obj_7.outputs.is_cut[i]).item() > 0]\n",
    "homophilies_4 = [unbiased_homophily(obj_4.inputs.A[i], obj_4.outputs.is_cut[i]) for i in range(batch_size*4) if torch.sum(obj_4.outputs.is_cut[i]).item() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies = {\n",
    "    \"graph_size\": [4, 7, 11, 13, 16],\n",
    "    \"homophilies\": [homophilies_4, homophilies_7, homophilies_11, homophilies_13, homophilies_16]\n",
    "}\n",
    "\n",
    "plot_homophilies(homophilies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo_reasoning.src.models.encoder import preprocess\n",
    "from algo_reasoning.src.specs import Location, Type, SPECS\n",
    "\n",
    "def accum_adj_matrix(adj_matrix, _input):\n",
    "    _input = _input.squeeze(-1)\n",
    "    adj_matrix += ((_input + _input.permute((0, 2, 1))) > 0.0)\n",
    "\n",
    "    return adj_matrix\n",
    "\n",
    "def build_adj_matrix(obj, batch_size, nb_nodes, algorithm, hint_step=None):\n",
    "    adj_mat = (torch.zeros((nb_nodes, nb_nodes), device=device)[None, :, :]).repeat(batch_size, 1, 1).bool()\n",
    "    \n",
    "    for k, value in obj.inputs:\n",
    "        if k not in SPECS[algorithm]:\n",
    "            continue\n",
    "            \n",
    "        _, loc, type_ = SPECS[algorithm][k]\n",
    "        _input = preprocess(value, type_, nb_nodes)\n",
    "\n",
    "        if loc == Location.NODE and type_ == Type.POINTER:\n",
    "            adj_mat = accum_adj_matrix(adj_mat, _input)\n",
    "                \n",
    "        elif loc == Location.EDGE and type_ == Type.MASK:\n",
    "            adj_mat = accum_adj_matrix(adj_mat, _input)\n",
    "\n",
    "    if hint_step is not None:\n",
    "        for k, value in obj.hints:\n",
    "            if k not in SPECS[algorithm]:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            _, loc, type_ = SPECS[algorithm][k]\n",
    "            \n",
    "            value = value[:, hint_step]\n",
    "            _input = preprocess(value, type_, nb_nodes)\n",
    "\n",
    "            if loc == Location.NODE and type_ == Type.POINTER:\n",
    "                adj_mat = accum_adj_matrix(adj_mat, _input)\n",
    "                    \n",
    "            elif loc == Location.EDGE and type_ == Type.MASK:\n",
    "                adj_mat = accum_adj_matrix(adj_mat, _input)\n",
    "\n",
    "    return adj_mat.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"activity_selector\"]\n",
    "\n",
    "batch_size = 128\n",
    "activity_selector_16 = CLRSDataset(algorithms, [16], batch_size, 1000, seed=7)\n",
    "activity_selector_13 = CLRSDataset(algorithms, [13], batch_size, 1000, seed=7)\n",
    "activity_selector_11 = CLRSDataset(algorithms, [11], batch_size, 1000, seed=7)\n",
    "activity_selector_7 = CLRSDataset(algorithms, [7], batch_size, 1000, seed=7)\n",
    "activity_selector_4 = CLRSDataset(algorithms, [4], batch_size, 1000, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_16 = next(iter(activity_selector_16))\n",
    "obj_13 = next(iter(activity_selector_13))\n",
    "obj_11 = next(iter(activity_selector_11))\n",
    "obj_7 = next(iter(activity_selector_7))\n",
    "obj_4 = next(iter(activity_selector_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat_16 = build_adj_matrix(obj_16, batch_size, 16, algorithms[0], hint_step=-1)\n",
    "adj_mat_13 = build_adj_matrix(obj_13, batch_size, 13, algorithms[0], hint_step=-1)\n",
    "adj_mat_11 = build_adj_matrix(obj_11, batch_size, 11, algorithms[0], hint_step=-1)\n",
    "adj_mat_7 = build_adj_matrix(obj_7, batch_size, 7, algorithms[0], hint_step=-1)\n",
    "adj_mat_4 = build_adj_matrix(obj_4, batch_size, 4, algorithms[0], hint_step=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies_16 = [unbiased_homophily(adj_mat_16[i], obj_16.outputs.selected[i]) for i in range(128) if torch.unique(obj_16.outputs.selected[i]).int().size(0) > 1]\n",
    "homophilies_13 = [unbiased_homophily(adj_mat_13[i], obj_13.outputs.selected[i]) for i in range(128) if torch.unique(obj_13.outputs.selected[i]).int().size(0) > 1]\n",
    "homophilies_11 = [unbiased_homophily(adj_mat_11[i], obj_11.outputs.selected[i]) for i in range(128) if torch.unique(obj_11.outputs.selected[i]).int().size(0) > 1]\n",
    "homophilies_7 = [unbiased_homophily(adj_mat_7[i], obj_7.outputs.selected[i]) for i in range(128) if torch.unique(obj_7.outputs.selected[i]).int().size(0) > 1]\n",
    "homophilies_4 = [unbiased_homophily(adj_mat_4[i], obj_4.outputs.selected[i]) for i in range(128) if torch.unique(obj_4.outputs.selected[i]).int().size(0) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies = {\n",
    "    \"graph_size\": [4, 7, 11, 13, 16],\n",
    "    \"homophilies\": [homophilies_4, homophilies_7, homophilies_11, homophilies_13, homophilies_16]\n",
    "}\n",
    "\n",
    "plot_homophilies(homophilies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"task_scheduling\"]\n",
    "\n",
    "batch_size = 128\n",
    "task_scheduling_16 = CLRSDataset(algorithms, [16], batch_size, 1000, seed=7)\n",
    "task_scheduling_13 = CLRSDataset(algorithms, [13], batch_size, 1000, seed=7)\n",
    "task_scheduling_11 = CLRSDataset(algorithms, [11], batch_size, 1000, seed=7)\n",
    "task_scheduling_7 = CLRSDataset(algorithms, [7], batch_size, 1000, seed=7)\n",
    "task_scheduling_4 = CLRSDataset(algorithms, [4], batch_size, 1000, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_16 = next(iter(task_scheduling_16))\n",
    "obj_13 = next(iter(task_scheduling_13))\n",
    "obj_11 = next(iter(task_scheduling_11))\n",
    "obj_7 = next(iter(task_scheduling_7))\n",
    "obj_4 = next(iter(task_scheduling_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat_16 = build_adj_matrix(obj_16, batch_size, 16, algorithms[0], hint_step=-1)\n",
    "adj_mat_13 = build_adj_matrix(obj_13, batch_size, 13, algorithms[0], hint_step=-1)\n",
    "adj_mat_11 = build_adj_matrix(obj_11, batch_size, 11, algorithms[0], hint_step=-1)\n",
    "adj_mat_7 = build_adj_matrix(obj_7, batch_size, 7, algorithms[0], hint_step=-1)\n",
    "adj_mat_4 = build_adj_matrix(obj_4, batch_size, 4, algorithms[0], hint_step=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies_16 = [unbiased_homophily(adj_mat_16[i], obj_16.outputs.selected[i]) for i in range(128) if torch.unique(obj_16.outputs.selected[i]).int().size(0) > 1]\n",
    "homophilies_13 = [unbiased_homophily(adj_mat_13[i], obj_13.outputs.selected[i]) for i in range(128) if torch.unique(obj_13.outputs.selected[i]).int().size(0) > 1]\n",
    "homophilies_11 = [unbiased_homophily(adj_mat_11[i], obj_11.outputs.selected[i]) for i in range(128) if torch.unique(obj_11.outputs.selected[i]).int().size(0) > 1]\n",
    "homophilies_7 = [unbiased_homophily(adj_mat_7[i], obj_7.outputs.selected[i]) for i in range(128) if torch.unique(obj_7.outputs.selected[i]).int().size(0) > 1]\n",
    "homophilies_4 = [unbiased_homophily(adj_mat_4[i], obj_4.outputs.selected[i]) for i in range(128) if torch.unique(obj_4.outputs.selected[i]).int().size(0) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies = {\n",
    "    \"graph_size\": [4, 7, 11, 13, 16],\n",
    "    \"homophilies\": [homophilies_4, homophilies_7, homophilies_11, homophilies_13, homophilies_16]\n",
    "}\n",
    "\n",
    "plot_homophilies(homophilies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graham Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"graham_scan\"]\n",
    "\n",
    "nb_nodes = 16\n",
    "batch_size = 128\n",
    "graham_scan = CLRSDataset(algorithms, [16], batch_size, 1000, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = next(iter(graham_scan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat = build_adj_matrix(obj, batch_size, nb_nodes, algorithms[0], hint_step=-1)\n",
    "adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies = [unbiased_homophily(adj_mat[i], obj.outputs.in_hull[i]) for i in range(128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(homophilies, kde=True, bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jarvis March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"jarvis_march\"]\n",
    "\n",
    "nb_nodes = 16\n",
    "batch_size = 128\n",
    "jarvis_march = CLRSDataset(algorithms, [16], batch_size, 1000, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = next(iter(jarvis_march))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat = build_adj_matrix(obj, batch_size, nb_nodes, algorithms[0], hint_step=-1)\n",
    "adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophilies = [unbiased_homophily(adj_mat[i], obj.outputs.in_hull[i]) for i in range(128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(homophilies, kde=True, bins=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
