{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from algo_reasoning.src.sampler import CLRSDataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device =  torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo_reasoning.src.models.network import EncodeProcessDecode\n",
    "from algo_reasoning.src.lightning.AlgorithmicReasoningTask import AlgorithmicReasoningTask \n",
    "from algo_reasoning.src.specs import CLRS_30_ALGS\n",
    "from algo_reasoning.src.losses.AlgorithmicReasoningLoss import AlgorithmicReasoningLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"dfs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = str(next(Path(f\"../checkpoints/{algorithms[0]}/\").glob(f\"{algorithms[0]}-PGN_noreg*\")))\n",
    "#ckpt_path = str(next(Path(f\"../checkpoints/{algorithms[0]}/\").glob(f\"{algorithms[0]}-mpnn*\")))\n",
    "\n",
    "model = EncodeProcessDecode(algorithms, processor='pgn')\n",
    "loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "model = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn, strict=False).model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating embeddings with model reg = 0.0\n",
    "\n",
    "ckpt_path = str(next(Path(f\"../checkpoints/checkpoints/{algorithms[0]}/\").glob(f\"{algorithms[0]}-hidden_reg=0.0*\")))\n",
    "\n",
    "model = EncodeProcessDecode(algorithms)\n",
    "loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "model_0 = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn).model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating embeddings with model reg = 0.0\n",
    "\n",
    "ckpt_path = str(next(Path(f\"../checkpoints/checkpoints/{algorithms[0]}/\").glob(f\"{algorithms[0]}-hidden_reg=0.1*\")))\n",
    "\n",
    "model = EncodeProcessDecode(algorithms)\n",
    "loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "model_1 = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn).model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Fourier Analysis of Algorithmic Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example: Graph Fourier Transform of BFS Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fourier_transform(embeddings, adj_matrix):\n",
    "    \"\"\"\n",
    "    Compute the Fourier Transform of the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "    Returns:\n",
    "        a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "    \"\"\"\n",
    "    degrees = torch.sum(adj_matrix, dim=1)\n",
    "    degree_matrix = torch.stack([torch.diag(degrees[d]) for d in range(degrees.size(0))], dim=0)\n",
    "    laplacian = degree_matrix - adj_matrix\n",
    "    \n",
    "    result = torch.linalg.eigh(laplacian)\n",
    "    eigenvalues = result.eigenvalues\n",
    "    eigenvectors = result.eigenvectors\n",
    "    \n",
    "    eigenvalues[torch.isclose(eigenvalues, torch.tensor(0.))] = 0.\n",
    "\n",
    "    return eigenvectors.transpose(-2, -1)@embeddings, eigenvectors, eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_distance(x):\n",
    "    \"\"\"\n",
    "    Compute the mean average distance of the x.\n",
    "\n",
    "    Args:\n",
    "        x: a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "    Returns:\n",
    "        a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_sim = torch.matmul(x, x.transpose(-2, -1))/(torch.norm(x, dim=-1).unsqueeze(-1)*torch.norm(x, dim=-1).unsqueeze(-2))\n",
    "    distance = 1 - embeddings_sim\n",
    "\n",
    "    mad = torch.mean(torch.mean(distance, dim=-1), dim=-1)\n",
    "\n",
    "    return mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "algorithm_args = {\n",
    "    'p': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "nb_nodes = 16\n",
    "ds = CLRSDataset(algorithms, nb_nodes, 32, 1000, seed=7, algorithms_args=algorithm_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = next(iter(ds)).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = obj.inputs.adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(obj)\n",
    "embeddings = output.hidden_embeddings\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_embeddings, eigenvectors, eigenvalues = fourier_transform(embeddings[:, -4], adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectors@(torch.diag_embed(eigenvalues)@(eigenvectors.transpose(-1, -2)@embeddings[:, -4])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_data = torch.mean(fourier_embeddings, dim=-1)\n",
    "\n",
    "plt.bar(x=[i for i in range(nb_nodes)], height=plot_data[11].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mad = [torch.mean(mean_average_distance(embeddings[:, i, :, :].squeeze()), dim=0).item() for i in range(embeddings.size(1))]\n",
    "plt.plot(mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = [torch.mean(mean_average_distance(embeddings[:, i, :, :].squeeze()), dim=0).item() for i in range(embeddings.size(1))]\n",
    "plt.plot(mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "difference_over_length = torch.mean(torch.abs(plot_data[:, :, 0] - torch.mean(plot_data[:, :, 1:])), dim=0)\n",
    "\n",
    "plt.plot(difference_over_length.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = torch.diag(torch.ones(nb_nodes, device=device)*nb_nodes) - torch.ones((nb_nodes, nb_nodes), device=device)\n",
    "_embeddings = embeddings.clone()[0, :, :]\n",
    "variability = torch.sum((_embeddings.transpose(1, 2)@laplacian)*_embeddings.transpose(1,2), dim=2)\n",
    "\n",
    "plt.plot(torch.mean(variability, dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean_corr_coef(embeddings):\n",
    "    mean_corr_coef = None\n",
    "    for i in range(embeddings.size(0)):\n",
    "        if mean_corr_coef is None:\n",
    "            mean_corr_coef = embeddings[i, 15].corrcoef()\n",
    "        else:\n",
    "            mean_corr_coef += embeddings[i, 15].corrcoef()\n",
    "\n",
    "    mean_corr_coef = mean_corr_coef/embeddings.size(0)\n",
    "\n",
    "    return mean_corr_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_mean_corr_coef(algos, model):\n",
    "    mean_corr = []\n",
    "    \n",
    "    for algo in CLRS_30_ALGS:\n",
    "        nb_nodes = 16\n",
    "        ds = CLRSDataset(algorithms, nb_nodes, 8, 1000, seed=7, algorithms_args=algorithm_args)\n",
    "    \n",
    "        obj = next(iter(ds)).to(device=device)\n",
    "    \n",
    "        output = model(obj)\n",
    "        embeddings = output.hidden_embeddings\n",
    "        \n",
    "        mean_corr.append(_mean_corr_coef(embeddings).mean())\n",
    "\n",
    "    return mean_corr\n",
    "\n",
    "mean_corr_coef = calculate_mean_corr_coef(CLRS_30_ALGS, model)\n",
    "mean_corr_coef_0 = calculate_mean_corr_coef(CLRS_30_ALGS, model_0)\n",
    "mean_corr_coef_1 = calculate_mean_corr_coef(CLRS_30_ALGS, model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_corr_df = pd.DataFrame({\"algoritmhs\": CLRS_30_ALGS, \n",
    "                             \"mean_corr_0.5\":mean_corr_coef, \n",
    "                             \"mean_corr_0.1\":mean_corr_coef_1,\n",
    "                             \"mean_corr_0.0\":mean_corr_coef_0})\n",
    "\n",
    "mean_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
