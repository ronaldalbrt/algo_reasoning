{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronaldalbert/Documents/env/algo_reasoning/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from algo_reasoning.src.sampler import CLRSDataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device =  torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo_reasoning.src.models.network import EncodeProcessDecode\n",
    "from algo_reasoning.src.lightning.AlgorithmicReasoningTask import AlgorithmicReasoningTask \n",
    "from algo_reasoning.src.specs import CLRS_30_ALGS\n",
    "from algo_reasoning.src.losses.AlgorithmicReasoningLoss import AlgorithmicReasoningLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"dfs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = str(next(Path(f\"../checkpoints/{algorithms[0]}/\").glob(f\"{algorithms[0]}-spectralmpnn0*\")))\n",
    "#ckpt_path = str(next(Path(f\"../checkpoints/{algorithms[0]}/\").glob(f\"{algorithms[0]}-mpnn*\")))\n",
    "\n",
    "model = EncodeProcessDecode(algorithms, processor='spectralmpnn2')\n",
    "loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "model = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn, strict=False).model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating embeddings with model reg = 0.0\n",
    "\n",
    "ckpt_path = str(next(Path(f\"../checkpoints/checkpoints/{algorithms[0]}/\").glob(f\"{algorithms[0]}-hidden_reg=0.0*\")))\n",
    "\n",
    "model = EncodeProcessDecode(algorithms)\n",
    "loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "model_0 = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn).model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating embeddings with model reg = 0.0\n",
    "\n",
    "ckpt_path = str(next(Path(f\"../checkpoints/checkpoints/{algorithms[0]}/\").glob(f\"{algorithms[0]}-hidden_reg=0.1*\")))\n",
    "\n",
    "model = EncodeProcessDecode(algorithms)\n",
    "loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "model_1 = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn).model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Fourier Analysis of Algorithmic Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example: Graph Fourier Transform of BFS Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fourier_transform(embeddings, adj_matrix):\n",
    "    \"\"\"\n",
    "    Compute the Fourier Transform of the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "    Returns:\n",
    "        a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "    \"\"\"\n",
    "    degrees = torch.sum(adj_matrix, dim=1)\n",
    "    degree_matrix = torch.stack([torch.diag(degrees[d]) for d in range(degrees.size(0))], dim=0)\n",
    "    laplacian = degree_matrix - adj_matrix\n",
    "    \n",
    "    result = torch.linalg.eigh(laplacian)\n",
    "    eigenvalues = result.eigenvalues\n",
    "    eigenvectors = result.eigenvectors\n",
    "    \n",
    "    eigenvalues[torch.isclose(eigenvalues, torch.tensor(0.))] = 0.\n",
    "\n",
    "    return eigenvectors.transpose(-2, -1)@embeddings, eigenvectors, eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_distance(x):\n",
    "    \"\"\"\n",
    "    Compute the mean average distance of the x.\n",
    "\n",
    "    Args:\n",
    "        x: a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "    Returns:\n",
    "        a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_sim = torch.matmul(x, x.transpose(-2, -1))/(torch.norm(x, dim=-1).unsqueeze(-1)*torch.norm(x, dim=-1).unsqueeze(-2))\n",
    "    distance = 1 - embeddings_sim\n",
    "\n",
    "    mad = torch.mean(torch.mean(distance, dim=-1), dim=-1)\n",
    "\n",
    "    return mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirichlet_energy(x, adj_matrix=None):\n",
    "    \"\"\"\n",
    "    Computes the Dirichlet Energy of the node Embeddings as defined by: https://arxiv.org/abs/2303.10993\n",
    "\n",
    "    Args:\n",
    "        x: a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "        adj_matrix: binary tensor of the graph adjacency matrix (sequence_length, sequence_length)\n",
    "\n",
    "    Returns:\n",
    "        a tensor of shape (batch_size, sequence_length)\n",
    "    \"\"\"\n",
    "    batch_size, nb_nodes, embedding_dim = x.size()\n",
    "    \n",
    "    if adj_matrix is None:\n",
    "        adj_matrix = torch.ones(batch_size, nb_nodes, nb_nodes, device=device)\n",
    "\n",
    "    degrees = torch.sum(adj_matrix, dim=1)\n",
    "    energy = 0\n",
    "    for i in range(nb_nodes):\n",
    "        node_diff = (x[:, i]/degrees[:,i].unsqueeze(-1)).unsqueeze(1) - x/degrees.unsqueeze(-1)\n",
    "        for j in range(nb_nodes):\n",
    "            differences = node_diff[adj_matrix[:, i].bool()]\n",
    "            diff_norms = torch.norm(differences, dim=1)\n",
    "            energy += torch.sum(diff_norms)\n",
    "\n",
    "    return torch.sqrt(energy/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "algorithm_args = {\n",
    "    'p': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "nb_nodes = 16\n",
    "ds = CLRSDataset(algorithms, nb_nodes, 32, 1000, seed=7, algorithms_args=algorithm_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = next(iter(ds)).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(obj)\n",
    "embeddings = output.hidden_embeddings\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_embeddings, eigenvectors, eigenvalues = fourier_transform(embeddings[:, -4], adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eigenvectors@(torch.diag_embed(eigenvalues)@(eigenvectors.transpose(-1, -2)@embeddings[:, -4])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_data = torch.mean(fourier_embeddings, dim=-1)\n",
    "\n",
    "plt.bar(x=[i for i in range(nb_nodes)], height=plot_data[11].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mad = [torch.mean(dirichlet_energy(embeddings[:, i, :, :].squeeze()), dim=0).item() for i in range(embeddings.size(1))]\n",
    "plt.plot(mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = [torch.mean(dirichlet_energy(embeddings[:, i, :, :].squeeze(), adj_matrix), dim=0).item() for i in range(embeddings.size(1))]\n",
    "plt.plot(mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "difference_over_length = torch.mean(torch.abs(plot_data[:, :, 0] - torch.mean(plot_data[:, :, 1:])), dim=0)\n",
    "\n",
    "plt.plot(difference_over_length.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = torch.diag(torch.ones(nb_nodes, device=device)*nb_nodes) - torch.ones((nb_nodes, nb_nodes), device=device)\n",
    "_embeddings = embeddings.clone()[0, :, :]\n",
    "variability = torch.sum((_embeddings.transpose(1, 2)@laplacian)*_embeddings.transpose(1,2), dim=2)\n",
    "\n",
    "plt.plot(torch.mean(variability, dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean_corr_coef(embeddings):\n",
    "    mean_corr_coef = None\n",
    "    for i in range(embeddings.size(0)):\n",
    "        if mean_corr_coef is None:\n",
    "            mean_corr_coef = embeddings[i, 15].corrcoef()\n",
    "        else:\n",
    "            mean_corr_coef += embeddings[i, 15].corrcoef()\n",
    "\n",
    "    mean_corr_coef = mean_corr_coef/embeddings.size(0)\n",
    "\n",
    "    return mean_corr_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_mean_corr_coef(algos, model):\n",
    "    mean_corr = []\n",
    "    \n",
    "    for algo in CLRS_30_ALGS:\n",
    "        nb_nodes = 16\n",
    "        ds = CLRSDataset(algorithms, nb_nodes, 8, 1000, seed=7, algorithms_args=algorithm_args)\n",
    "    \n",
    "        obj = next(iter(ds)).to(device=device)\n",
    "    \n",
    "        output = model(obj)\n",
    "        embeddings = output.hidden_embeddings\n",
    "        \n",
    "        mean_corr.append(_mean_corr_coef(embeddings).mean())\n",
    "\n",
    "    return mean_corr\n",
    "\n",
    "mean_corr_coef = calculate_mean_corr_coef(CLRS_30_ALGS, model)\n",
    "mean_corr_coef_0 = calculate_mean_corr_coef(CLRS_30_ALGS, model_0)\n",
    "mean_corr_coef_1 = calculate_mean_corr_coef(CLRS_30_ALGS, model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_corr_df = pd.DataFrame({\"algoritmhs\": CLRS_30_ALGS, \n",
    "                             \"mean_corr_0.5\":mean_corr_coef, \n",
    "                             \"mean_corr_0.1\":mean_corr_coef_1,\n",
    "                             \"mean_corr_0.0\":mean_corr_coef_0})\n",
    "\n",
    "mean_corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low OOD Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def load_algorithm_args(args_file):\n",
    "    with open(args_file, 'r') as f:\n",
    "        args = yaml.safe_load(f)\n",
    "\n",
    "    return args\n",
    "\n",
    "algorithm_args = load_algorithm_args(\"../algorithm_args/default.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articulation_points\n",
      "activity_selector\n",
      "binary_search\n",
      "bubble_sort\n",
      "dfs\n",
      "find_maximum_subarray_kadane\n",
      "floyd_warshall\n",
      "heapsort\n",
      "insertion_sort\n",
      "kmp_matcher\n",
      "matrix_chain_order\n",
      "mst_kruskal\n",
      "mst_prim\n",
      "naive_string_matcher\n",
      "quickselect\n",
      "quicksort\n",
      "strongly_connected_components\n",
      "task_scheduling\n",
      "topological_sort\n"
     ]
    }
   ],
   "source": [
    "low_ood_algorithms = [\"articulation_points\", \"activity_selector\", \"binary_search\", \"bubble_sort\", \"dfs\",\n",
    "                     \"find_maximum_subarray_kadane\", \"floyd_warshall\", \"heapsort\", \"insertion_sort\", \"kmp_matcher\",\n",
    "                     \"matrix_chain_order\", \"mst_kruskal\", \"mst_prim\", \"naive_string_matcher\", \"quickselect\",\n",
    "                     \"quicksort\", \"strongly_connected_components\", \"task_scheduling\", \"topological_sort\"]\n",
    "\n",
    "nb_nodes = 16\n",
    "\n",
    "dirichlet_en = dict()\n",
    "for algorithm in low_ood_algorithms:\n",
    "    print(algorithm)\n",
    "    ckpt_path = str(next(Path(f\"../_checkpoints/{algorithm}/\").glob(f\"{algorithm}-hidden_reg=0.0*\")))\n",
    "    model = EncodeProcessDecode([algorithm], processor='mpnn')\n",
    "\n",
    "    loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "    model = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn, strict=False).model.to(device)\n",
    "\n",
    "\n",
    "    ds = CLRSDataset([algorithm], nb_nodes, 8, 1000, seed=7, algorithms_args=algorithm_args)\n",
    "    obj = next(iter(ds)).to(device=device)\n",
    "    \n",
    "    output = model(obj)\n",
    "    embeddings = output.hidden_embeddings\n",
    "\n",
    "    dirichlet_en[algorithm] = [dirichlet_energy(embeddings[:, i, :, :].squeeze()).item() for i in range(embeddings.size(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43.80147933959961,\n",
       " 42.86289596557617,\n",
       " 53.79662322998047,\n",
       " 44.582603454589844,\n",
       " 49.861019134521484,\n",
       " 51.77833557128906,\n",
       " 47.81977081298828,\n",
       " 41.594974517822266,\n",
       " 45.00823211669922,\n",
       " 63.96101760864258,\n",
       " 52.29963684082031,\n",
       " 35.246368408203125,\n",
       " 42.25633239746094,\n",
       " 64.68964385986328,\n",
       " 38.785301208496094,\n",
       " 43.29964065551758,\n",
       " 45.81415939331055,\n",
       " 51.948089599609375,\n",
       " 49.73229217529297]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet_avg = []\n",
    "for key in dirichlet_en.keys():\n",
    "    dirichlet_avg.append(torch.tensor(dirichlet_en[key]).mean().item())\n",
    "dirichlet_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bellman_ford\n",
      "bfs\n",
      "bridges\n",
      "dag_shortest_paths\n",
      "dijkstra\n",
      "graham_scan\n",
      "jarvis_march\n",
      "lcs_length\n",
      "minimum\n",
      "optimal_bst\n",
      "segments_intersect\n"
     ]
    }
   ],
   "source": [
    "from algo_reasoning.src.specs import CLRS_30_ALGS\n",
    "\n",
    "high_ood_algorithms = [alg for alg in CLRS_30_ALGS if alg not in low_ood_algorithms]\n",
    "\n",
    "high_ood_en = dict()\n",
    "\n",
    "for algorithm in high_ood_algorithms:\n",
    "    print(algorithm)\n",
    "    ckpt_path = str(next(Path(f\"../_checkpoints/{algorithm}/\").glob(f\"{algorithm}-hidden_reg=0.0*\")))\n",
    "    model = EncodeProcessDecode([algorithm], processor='mpnn')\n",
    "\n",
    "    loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "    model = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn, strict=False).model.to(device)\n",
    "\n",
    "\n",
    "    ds = CLRSDataset([algorithm], nb_nodes, 8, 1000, seed=7, algorithms_args=algorithm_args)\n",
    "    obj = next(iter(ds)).to(device=device)\n",
    "    \n",
    "    output = model(obj)\n",
    "    embeddings = output.hidden_embeddings\n",
    "\n",
    "    high_ood_en[algorithm] = [dirichlet_energy(embeddings[:, i, :, :].squeeze()).item() for i in range(embeddings.size(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.158023834228516,\n",
       " 38.2791748046875,\n",
       " 44.376800537109375,\n",
       " 44.11208724975586,\n",
       " 45.68049621582031,\n",
       " 54.25910186767578,\n",
       " 51.69864273071289,\n",
       " 56.80711364746094,\n",
       " 43.57819366455078,\n",
       " 45.41507339477539,\n",
       " 13.613958358764648]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet_avg = []\n",
    "for key in high_ood_en.keys():\n",
    "    dirichlet_avg.append(torch.tensor(high_ood_en[key]).mean().item())\n",
    "dirichlet_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
