{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from algo_reasoning.src.sampler import CLRSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo_reasoning.src.models.network import EncodeProcessDecode\n",
    "from algo_reasoning.src.lightning.AlgorithmicReasoningTask import AlgorithmicReasoningTask \n",
    "from algo_reasoning.src.specs import CLRS_30_ALGS\n",
    "from algo_reasoning.src.losses.AlgorithmicReasoningLoss import AlgorithmicReasoningLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../checkpoints/Generalist/Generalist-epoch=49-val_loss=0.76.ckpt\"\n",
    "\n",
    "model = EncodeProcessDecode(CLRS_30_ALGS)\n",
    "loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "model = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Fourier Analysis of Algorithmic Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example: Graph Fourier Transform of BFS Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fourier_transform(embeddings, nb_nodes):\n",
    "    \"\"\"\n",
    "    Compute the Fourier Transform of the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "    Returns:\n",
    "        a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    laplacian = torch.diag(torch.ones(nb_nodes, device=device)*nb_nodes) - torch.ones((nb_nodes, nb_nodes), device=device)\n",
    "    result = torch.linalg.eigh(laplacian)\n",
    "    eigenvalues = result.eigenvalues\n",
    "    eigenvectors = result.eigenvectors\n",
    "    \n",
    "    eigenvalues[torch.isclose(eigenvalues, torch.tensor(0.))] = 0.\n",
    "\n",
    "    return eigenvectors.T@embeddings, eigenvectors, eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "algorithm_args = {\n",
    "    'p': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "algorithms = [\"jarvis_march\"]\n",
    "nb_nodes = 16\n",
    "ds = CLRSDataset(algorithms, nb_nodes, 200, 1000, seed=7, algorithms_args=algorithm_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = next(iter(ds)).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(obj)\n",
    "embeddings = output.hidden_embeddings\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_embeddings, eigenvectors, eigenvalues = fourier_transform(embeddings, nb_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_data = torch.mean(torch.abs(fourier_embeddings), dim=3)\n",
    "\n",
    "plt.bar(x=[i for i in range(nb_nodes)], height=plot_data[0,0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "difference_over_length = torch.mean(torch.abs(plot_data[:, :, 0] - torch.mean(plot_data[:, :, 1:])), dim=0)\n",
    "\n",
    "plt.plot(difference_over_length.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = torch.diag(torch.ones(nb_nodes, device=device)*nb_nodes) - torch.ones((nb_nodes, nb_nodes), device=device)\n",
    "_embeddings = embeddings.clone()[60, :, :]\n",
    "variability = torch.sum((_embeddings.transpose(1, 2)@laplacian)*_embeddings.transpose(1,2), dim=2)\n",
    "\n",
    "plt.plot(torch.mean(variability, dim=1).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate using pyGSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pygsp.graphs.fullconnected import FullConnected\n",
    "from pygsp.graphs.erdosrenyi import ErdosRenyi\n",
    "from pygsp.graphs.grid2d import Grid2d\n",
    "\n",
    "G = FullConnected(N=nb_nodes)\n",
    "G.compute_fourier_basis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_embeddings = embeddings[0, 0,  :, :].detach().numpy()\n",
    "output  = G.gft(test_embeddings)\n",
    "\n",
    "plot_data = np.mean(np.abs(output), axis=1)\n",
    "plt.bar(x=[i for i in range(nb_nodes)], height=plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_embeddings = torch.randn(16, 128)#embeddings[0, 0,  :, :].detach().numpy()\n",
    "output  = G.gft(test_embeddings)\n",
    "\n",
    "plot_data = np.mean(np.abs(output), axis=1)\n",
    "plt.bar(x=[i for i in range(nb_nodes)], height=plot_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
