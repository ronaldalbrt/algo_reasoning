{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from algo_reasoning.src.sampler import CLRSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo_reasoning.src.models.network import EncodeProcessDecode\n",
    "from algo_reasoning.src.lightning.AlgorithmicReasoningTask import AlgorithmicReasoningTask \n",
    "from algo_reasoning.src.specs import CLRS_30_ALGS\n",
    "from algo_reasoning.src.losses.AlgorithmicReasoningLoss import AlgorithmicReasoningLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronald/Documents/env/algo_reasoning/lib/python3.12/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/home/ronald/Documents/env/algo_reasoning/lib/python3.12/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.4.0, which is newer than your current Lightning version: v2.2.4\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"../checkpoints/Generalist/Generalist-epoch=49-val_loss=0.76.ckpt\"\n",
    "\n",
    "model = EncodeProcessDecode(CLRS_30_ALGS)\n",
    "loss_fn = AlgorithmicReasoningLoss()\n",
    "\n",
    "model = AlgorithmicReasoningTask.load_from_checkpoint(ckpt_path, model=model, loss_fn=loss_fn).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Fourier Analysis of Algorithmic Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example: Graph Fourier Transform of BFS Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_transform(embeddings, nb_nodes):\n",
    "    \"\"\"\n",
    "    Compute the Fourier Transform of the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "    Returns:\n",
    "        a tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the eigenvectors of the Laplacian matrix\n",
    "    # of the graph, only complete graphs are considered in the MPNN processor model.\n",
    "\n",
    "    eigenvectors = []\n",
    "    eigenvectors.append(torch.ones(nb_nodes, device=device)/torch.sqrt(torch.tensor(nb_nodes, device=device)))\n",
    "    for i in range(1, nb_nodes):\n",
    "        eig_v = torch.ones(nb_nodes, device=device)*-1\n",
    "        eig_v[i] = nb_nodes-1\n",
    "\n",
    "        eig_v = eig_v/torch.norm(eig_v)\n",
    "        eigenvectors.append(eig_v)\n",
    "\n",
    "\n",
    "    eigenvectors = torch.stack(eigenvectors, dim=0)\n",
    "\n",
    "    eigenvalues = torch.ones(nb_nodes, device=device) * 16\n",
    "    eigenvalues[0] = 0\n",
    "\n",
    "    # Compute the Fourier Transform of the embeddings\n",
    "    fourier_embeddings = eigenvectors@embeddings\n",
    "\n",
    "    return fourier_embeddings, eigenvectors, eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "algorithm_args = {\n",
    "    'p': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "algorithms = [\"bfs\"]\n",
    "nb_nodes = 16\n",
    "ds = CLRSDataset(algorithms, nb_nodes, 1, 1000, seed=7, algorithms_args=algorithm_args)\n",
    "obj = next(iter(ds)).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 16, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(obj)\n",
    "embeddings = output.hidden_embeddings\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_embeddings, eigenvectors, eigenvalues = fourier_transform(embeddings, nb_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(eigenvectors[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = torch.diag(torch.ones(nb_nodes, device=device)*16) - torch.ones((16, 16), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.linalg.eig(laplacian)\n",
    "eigenvalues = result.eigenvalues\n",
    "eigenvectors = result.eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1189+0.j,  0.3462+0.j,  0.3086+0.j, -0.3027+0.j, -0.4038+0.j,  0.0815+0.j,\n",
       "        -0.0569+0.j,  0.1482+0.j,  0.1669+0.j, -0.0773+0.j, -0.0693+0.j,  0.2493+0.j,\n",
       "        -0.3306+0.j, -0.3621+0.j,  0.3756+0.j,  0.0452+0.j], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors[:, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.3070e-01,  7.2455e-02, -4.4301e-01,  ...,  4.4498e-01,\n",
       "           -1.2940e-01, -1.4472e-01],\n",
       "          [ 7.3801e-02,  1.4629e+00,  1.5231e-01,  ..., -4.0338e-01,\n",
       "            3.2576e-03,  9.4393e-01],\n",
       "          [ 4.6021e-02,  4.1144e-01,  7.8297e-02,  ...,  3.8939e-01,\n",
       "           -4.6680e-02, -1.2233e-01],\n",
       "          ...,\n",
       "          [ 6.5689e-02, -6.7532e-01,  1.3070e-01,  ..., -4.4014e-01,\n",
       "           -1.1326e-02, -7.7330e-02],\n",
       "          [ 6.7513e-02, -7.5080e-01,  1.3556e-01,  ..., -4.8578e-01,\n",
       "           -8.0463e-03, -7.3156e-02],\n",
       "          [ 7.0312e-02, -8.2965e-01,  1.4302e-01,  ..., -5.9903e-01,\n",
       "           -3.0136e-03, -6.6751e-02]],\n",
       "\n",
       "         [[-2.2756e-01, -5.7270e-01, -4.4992e-01,  ..., -3.8418e-01,\n",
       "           -1.6312e-01, -3.0246e-01],\n",
       "          [ 9.0792e-02,  2.5714e-01,  2.1447e-01,  ..., -9.7786e-02,\n",
       "            7.7334e-02,  1.6251e-01],\n",
       "          [ 4.6231e-02,  1.2516e-01,  9.5738e-02,  ...,  3.0683e-01,\n",
       "           -2.7702e-03,  6.0550e-02],\n",
       "          ...,\n",
       "          [ 4.5460e-02,  1.2288e-01,  9.3683e-02,  ..., -6.7001e-02,\n",
       "           -4.1564e-03,  5.8785e-02],\n",
       "          [ 4.6572e-02,  1.2617e-01,  9.6647e-02,  ..., -1.3394e-01,\n",
       "           -2.1563e-03,  6.1331e-02],\n",
       "          [ 4.7674e-02,  1.2943e-01,  9.9584e-02,  ..., -1.4121e-01,\n",
       "           -1.7520e-04,  6.3853e-02]],\n",
       "\n",
       "         [[ 1.4376e-02, -5.1531e-01,  6.6019e-01,  ..., -4.4069e-01,\n",
       "           -1.6498e-01, -2.5813e-01],\n",
       "          [ 4.2859e-01,  2.1304e-01, -9.9586e-01,  ...,  2.3159e-02,\n",
       "            9.1145e-02,  1.2844e-01],\n",
       "          [ 3.5217e-01,  1.9475e-01,  3.7050e+00,  ...,  6.3122e-03,\n",
       "            8.0042e-02,  1.1431e-01],\n",
       "          ...,\n",
       "          [-2.1211e-01,  8.9031e-02, -1.1074e+00,  ...,  1.4226e-02,\n",
       "            1.5878e-02,  3.2639e-02],\n",
       "          [-2.1161e-01,  9.0529e-02, -1.1061e+00,  ..., -1.1271e-02,\n",
       "            1.6787e-02,  3.3796e-02],\n",
       "          [-2.1099e-01,  9.2357e-02, -1.1044e+00,  ..., -6.5166e-02,\n",
       "            1.7896e-02,  3.5208e-02]],\n",
       "\n",
       "         [[ 2.6779e-01, -4.7354e-01,  1.5611e+00,  ..., -4.3840e-01,\n",
       "           -1.3962e-01, -2.2586e-01],\n",
       "          [ 4.9802e-01,  1.7027e-01, -2.5676e+00,  ...,  1.4671e-01,\n",
       "            6.5188e-02,  9.5404e-02],\n",
       "          [ 5.6972e-01,  1.3160e-01, -7.1542e-01,  ...,  1.1110e-01,\n",
       "            4.1715e-02,  6.5526e-02],\n",
       "          ...,\n",
       "          [-4.4189e-01,  1.2188e-01,  1.2000e+00,  ...,  1.0214e-01,\n",
       "            3.5814e-02,  5.8015e-02],\n",
       "          [-4.5475e-01,  1.2515e-01,  1.2221e+00,  ...,  1.0516e-01,\n",
       "            3.7799e-02,  6.0541e-02],\n",
       "          [-4.8848e-01,  1.2491e-01,  1.2639e+00,  ...,  1.0494e-01,\n",
       "            3.7656e-02,  6.0359e-02]],\n",
       "\n",
       "         [[ 6.5509e-01, -4.5430e-01,  9.5071e-01,  ..., -4.3660e-01,\n",
       "           -1.2795e-01, -2.1099e-01],\n",
       "          [-2.4988e-02,  1.4874e-01, -1.1828e+00,  ...,  1.4046e-01,\n",
       "            5.2119e-02,  7.8769e-02],\n",
       "          [ 2.9361e-01,  1.3125e-01,  6.3970e-01,  ...,  1.2435e-01,\n",
       "            4.1501e-02,  6.5254e-02],\n",
       "          ...,\n",
       "          [-3.1287e-01,  9.7319e-02, -7.0032e-01,  ...,  9.3104e-02,\n",
       "            2.0908e-02,  3.9041e-02],\n",
       "          [-2.6033e-01,  9.8430e-02, -8.1402e-01,  ...,  9.4127e-02,\n",
       "            2.1582e-02,  3.9900e-02],\n",
       "          [-2.9307e-01,  9.7993e-02, -7.9440e-01,  ...,  9.3724e-02,\n",
       "            2.1317e-02,  3.9562e-02]]]], device='cuda:0',\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors@fourier_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
