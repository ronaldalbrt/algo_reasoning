{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify effect of Hidden Similarity Regularization on Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hidden_reg_df = pd.read_csv(\"../results/hidden_reg.csv\", delimiter=\";\")\n",
    "hidden_reg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from algo_reasoning.src.sampler import CLRSDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_algorithm_args(args_file):\n",
    "    with open(args_file, 'r') as f:\n",
    "        args = yaml.safe_load(f)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing effect of Hidden Regularization to Algorithm Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_args = load_algorithm_args(\"../algorithm_args/default.yaml\")\n",
    "hidden_reg_df[\"max_length\"] = pd.Series([0] * len(hidden_reg_df))\n",
    "\n",
    "for alg in hidden_reg_df.algorithm:\n",
    "    print(\"Generating sample for: \", alg)\n",
    "    algorithms = [alg]\n",
    "    nb_nodes = 64\n",
    "    ds = CLRSDataset(algorithms, nb_nodes, 1, 1000, seed=7, algorithms_args=algorithm_args)\n",
    "    obj = next(iter(ds)).to(device=device)\n",
    "\n",
    "    hidden_reg_df.loc[hidden_reg_df.algorithm == alg, [\"max_length\"]] =  obj.max_length.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_1_effect = hidden_reg_df[\"0.1_test\"] - hidden_reg_df[\"0.0_test\"]\n",
    "reg_5_effect = hidden_reg_df[\"0.5_test\"] - hidden_reg_df[\"0.0_test\"]\n",
    "\n",
    "ood_gap_reg_0 = hidden_reg_df[\"0.0_val\"] - hidden_reg_df[\"0.0_test\"]\n",
    "ood_gap_reg_1 = hidden_reg_df[\"0.1_val\"] - hidden_reg_df[\"0.1_test\"]\n",
    "ood_gap_reg_5 = hidden_reg_df[\"0.5_val\"] - hidden_reg_df[\"0.5_test\"]\n",
    "\n",
    "hidden_reg_df[\"reg_0.1_effect\"] = reg_1_effect\n",
    "hidden_reg_df[\"reg_0.5_effect\"] = reg_5_effect\n",
    "hidden_reg_df[\"ood_gap_0.0\"] = ood_gap_reg_0\n",
    "hidden_reg_df[\"ood_gap_0.1\"] = ood_gap_reg_1\n",
    "hidden_reg_df[\"ood_gap_0.5\"] = ood_gap_reg_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_reg_df[[\"reg_0.1_effect\", \"reg_0.5_effect\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_reg_df[[\"0.0_test\", \"0.1_test\", \"0.5_test\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_reg_df[[\"ood_gap_0.0\", \"ood_gap_0.1\", \"ood_gap_0.5\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_corr = hidden_reg_df[hidden_reg_df.columns.difference(['algorithm'])].corr()\n",
    "\n",
    "_corr[\"max_length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect by Algorithm Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = {\n",
    "    \"divide_and_conquer\": [\"find_maximum_subarray_kadane\"],\n",
    "    \"dynamic_programming\": [\"matrix_chain_order\", \"lcs_length\", \"optimal_bst\"],\n",
    "    \"geometry\": [\"segments_intersect\", \"graham_scan\", \"jarvis_march\"],\n",
    "    \"graphs\": [\"dfs\", \"bfs\", \"topological_sort\", \"articulation_points\", \"bridges\", \"strongly_connected_components\", \"mst_kruskal\", \"mst_prim\", \"bellman_ford\", \"dijkstra\", \"dag_shortest_paths\", \"floyd_warshall\"],\n",
    "    \"greedy\": [\"activity_selector\", \"task_scheduling\"], \n",
    "    \"searching\": [\"minimum\", \"binary_search\", \"quickselect\"],\n",
    "    \"sorting\": [\"insertion_sort\", \"bubble_sort\", \"heapsort\", \"quicksort\"],\n",
    "    \"strings\": [\"naive_string_matcher\", \"kmp_matcher\"]\n",
    "}\n",
    "\n",
    "def get_algo_type(algo):\n",
    "    for _type in type_dict.keys():\n",
    "        print\n",
    "        if algo in type_dict[_type]:\n",
    "            return _type\n",
    "        \n",
    "hidden_reg_df[\"_type\"] = hidden_reg_df.algorithm.apply(get_algo_type)\n",
    "agg_df = hidden_reg_df[hidden_reg_df.columns.difference(['algorithm'])].groupby(['_type']).mean()\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df[[\"ood_gap_0.0\", \"ood_gap_0.1\", \"ood_gap_0.5\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect by Output Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo_reasoning.src.specs import SPECS, Stage\n",
    "\n",
    "def get_output_type(algo):\n",
    "    for k, v in SPECS[algo].items():\n",
    "        stage, _, _type = v\n",
    "\n",
    "        if stage == Stage.OUTPUT:\n",
    "            return _type\n",
    "        \n",
    "hidden_reg_df[\"_output_type\"] = hidden_reg_df.algorithm.apply(get_output_type)\n",
    "hidden_reg_df\n",
    "output_agg_df = hidden_reg_df[hidden_reg_df.columns.difference(['algorithm', \"_type\"])].groupby(['_output_type']).mean()\n",
    "output_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_agg_df[[\"ood_gap_0.0\", \"ood_gap_0.1\", \"ood_gap_0.5\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_agg_df[[\"0.0_test\", \"0.1_test\", \"0.5_test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
